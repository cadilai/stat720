---
title: "STATS720 - assignment 1"
author: "Lai Ka Yin 400219450"
format: pdf
editor: visual
fontsize: 11pt
geometry: 
  - margin = 1in
linestretch: 1.5
execute: 
  eval: false
---

## load the required libraries

**BMB**: packages, not libraries ... (see [here](https://stackoverflow.com/questions/26900228/what-is-the-difference-between-a-library-and-a-package-in-r))

```{r}
library(dplyr)
library(magrittr)
library(stringr)
library(ggplot2)
library(faraway)
library(dotwhisker)
library(performance)
library(mlbench)
library(see)
library(emmeans)
library(effects)
library(pracma)
```

## 1. Data Set

```{r}
data("attitude")
```

The data set chosen is "attitude". Here are the variables below:

1.  rating: Overall rating

2.  complaints: Handling of employee complaints

3.  privileges: Does not allow special privileges

4.  learning: Opportunity to learn

5.  raises: Raises based on performance

6.  critical: Too critical

7.  advance: Advancement

-   Predictor variables: 'complains', 'learning', 'privileges', 'raises', 'critical', 'advance'

-   Response variable: 'rating'

The response variable is using units. For all predictor variable, a range of 0-10 would consider as a reasonable threshold for a small change in that variable. **BMB**: these words don't really make sense? What does "using units" mean? How do you know that 0-10 is small?

**Fit a linear regression model**

To fit a linear regression model, the four predictors variables included are 'complains', 'learning' 'raises', 'advance'.

**BMB**: how did you decide on these?

```{r}
m1<- lm(rating ~ complaints + learning + raises + critical , data=attitude)
```

**Diagnose model**

```{r}
par(mfrow=c(2,2))
plot(m1)
```

In the residual vs fitted plot, residuals are equally spread and follow a roughly linear pattern around the red line. Although the red line deviates from an exactly horizontal line but not severely so it can be declare that no non-linear relationships appears and a linear regression model is appropriate for this data set. From normal Q-Q plot, we can observe that points generally fall along the straight diagonal line, although observation #6, #12, #23 deviate a little off the line at the end of the tail, it is not enough to indicate that residuals are non-normally distributed. In the plot of Residuals vs Leverage, there is no observation lies outside of the dashed line which is cook's distance, it shows that there is no influential case. On the other hand, the scale-location plot reveals that residuals are spreading wider along the x-axis between 60 and 70, so the red line is not horizontal at all and shows a steep angle which may results in violation of the assumption of equal variance in this case. As a result, model adjustment may be needed.

**BMB**: largest three residuals are always labeled. Q-Q plot is thin-tailed.

**Adjustment**

To adjust the model, log transformation is carried out.

**BMB**: this log-transforms the response and *all* of the predictors. Did you know that? is that what you meant to do?

```{r}
attitude_log <- log(attitude)
m2<- lm(rating ~ complaints + learning + raises + critical , data=attitude_log )
#check model again
par(mfrow=c(2,2))
plot(m2)
```

The normal Q-Q plot shows that points fall better along the line after log transformation which indicates that the model is fitted better.

**BMB**: doesn't seem to have fixed the scale-location plot though  ... ???

**Show a coefficient plot of the result.**

```{r}
dotwhisker::dwplot(m2) + geom_vline(xintercept = 0, lty = 2) +
labs(title = "coefficient plot")
```

For this case, predictors are not scaled and centered because predictor variables for a rating have a meaningful zero value. **BMB**: this explains not centering, not not-scaling ... The default confidence interval is 95%, from the plot, with the dashed line at 0, 3 of the estimates larger than 0. Besides, we can see that coefficients of 'complaints' is highly significant at the 5% level because the interval doesn't contain 0.

**BMB**: this is just a restatement of the significance values from a summary table ...

**Effects Plot**

```{r}
effects::allEffects(m2)
plot(allEffects(m2), grid = TRUE)
```

The effect plots represents the response as a linear function of effects of responsive and predictor variables. From the plot, except 'raises', other three predictor variables including 'complaints', 'learning' and 'critical' show a positive relationship with response variable 'rating'. Among all, 'complaints' demonstrates the largest correlation with response variable while 'critical' performs the least. On the other hand, predictor variable 'raises' demonstrates a slightly inverse relationship that when higher rating in 'raises', slightly lower in 'rating'.

## 2. Before-after-control-impact (BACI)

First, create a data frame with two sampling types (Control and Impact) in two time periods (Before and After), then set up the minimal model matrix.

```{r}
# Create a data frame with the design variables
BACI <- data.frame(
  Period = factor(rep(c("Before", "After"), each = 2)),  
  Treatment = factor(rep(c("Control", "Impact"), times = 2))  
)

# Create the minimal model matrix using model.matrix
minimal <- model.matrix(~ Period * Treatment, BACI)
head(minimal)
```

Now, construct the and contrast matrix and inverse contrast matrix.

```{r}
#construct contrast matrix
C <- cbind(1, contr.treatment(4)) 
print(C)
```

```{r}
#inverse contrast matrix
inv_C <- solve(C)
print(inv_C)
```

Compare the model matrix with the results of the models.

```{r}
# ~ Period*Treatment  
eg1 <- expand.grid(minimal, C, inv_C)
print(eg1)
# ~ 0 + Period:Treatment
minimal_0 <- model.matrix(~ 0 + Period:Treatment, BACI)
eg2 <- expand.grid(minimal_0, C, inv_C)
print(eg2)
```

**BMB**: you never constructed the 'custom' inverse-contrast/contrast matrices, which are most of the point of this exercise ...

## 3. Simulation Exercise

A function for simulating data for a quadratic regression is modeled.

```{r}
# Model for simulating data 
sim_fun <- function(n = 100, true_slope = 1, sd = 1, intercept = 0) {
  x <- runif(n)
  y <- rnorm(n, intercept + true_slope * x^2, sd = sd)
  data.frame(x, y)
}
```

For simulation, alpha will be assumed as 0.05.

```{r}
# Function to run simulations with quadratic relationship
run_sim <- function(n = 100, true_slope = 1, sd = 1, intercept = 0, alpha=0.05, n_sim = 1000) {

  for (i in 1:n_sim) {
    # Simulate data
    data <- sim_fun(n = n, true_slope = true_slope, sd = sd)
    
    # A linear model 'm'
    m <- lm(y ~ x, data = data)
    
    # Extract slope of linear model
    slope <- coef(m)[2]
    
    # Calculate bias
    bias <- slope - true_slope
    results$Bias[i] <- bias
    
    # Calculate RMSE
    rm_se <- sqrt(mean((slope - true_slope)^2))
    results$RMSE[i] <- rm_se
    
    # Calculate p-value and check if p-value is less than alpha
    p_value <- coef(summary(m))[2, "Pr(>|t|)"]
    results$Power[i] <- p_value < 0.05 
    
    # Calculate coverage
    conf_interval <- confint(m)[2, ]
    between <- conf_interval[1] < true_slope & true_slope < conf_interval[2]
    results$Coverage[i] <- between
  }
  
  return(results)
}

```

Run a simulation with a quadratic relationship.

```{r}
#|  eval: true
set.seed(300)
results <- run_sim(n_sim = 1000, n = 100, true_slope = 2, sd = 2)

#summary of results
summary(results)

```

**BMB**: this code is not reproducible!

**Assumption to violate**

Linearity is violated as the simulation is for quadratic relationship instead of linear relationship. Here is the table comparing effect of several different levels of violation to on the bias, RMSE, power, and coverage of linear regression.

| Bias             | RMSE              | Power         | Coverage      |
|------------------|:------------------|:--------------|:--------------|
| Min. :-2.14540   | Min. :0.0003962   | Min. :0.000   | Min. :0.000   |
| 1st Qu.:-0.49650 | 1st Qu.:0.2307386 | 1st Qu.:1.000 | 1st Qu.:1.000 |
| Median :-0.02652 | Median :0.4695520 | Median :1.000 | Median :1.000 |
| Mean :-0.02291   | Mean :0.5648399   | Mean :0.796   | Mean :0.951   |
| 3rd Qu.: 0.44127 | 3rd Qu.:0.8189966 | 3rd Qu.:1.000 | 3rd Qu.:1.000 |
| Max. : 2.24764   | Max. :2.2476362   | Max. :1.000   | Max. :1.000   |
